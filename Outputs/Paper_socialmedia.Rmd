---
title: "Paper_social media"
author: "Dan Xu"
date: "3/26/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, echo=FALSE,message=FALSE,warning=FALSE}
#Load libraries 
library(ggplot2)
library(tidyverse) # recoding
library(janitor)
library(kableExtra)
```


```{r, echo=FALSE,message=FALSE,warning=FALSE}
# Save the post_stratification survey as a .rData file remember to do this 
 Survey <- read.csv("/Users/dans/Documents/Github/Social_media_fake_news/Inputs/Data/113992-V1/election-media-JEP-replication/source/raw/Inputs/Data/PostElectionSurvey/Sheet_1.csv",header = TRUE, sep = ",")
```
```{r, echo=FALSE,message=FALSE,warning=FALSE}
# The first 11 coluns are not related to the survey, therefore I removed them. 
Survey_clean <-
  Survey[, -c(1:11)]
```


```{r, echo=FALSE,message=FALSE,warning=FALSE}
# Rename cols/variables 
# How often do you get news from the following channels. 
Survey_clean <- 
  as_tibble(Survey_clean) %>% 
  janitor::clean_names() %>% 
  rename(social_media = "how_often_do_you",# get news from social media
         web_ap = "x", #Get news from a website or app?
         partyid = "before_the_2016_election_did_you_consider_yourself_a_republican_a_democrat_an_independent_or_what",
         vote_who = "who_did_you_vote_for_in_the_2016_presidential_election",
         vote_when = "when_did_you_make_up_your_mind_about_who_to_vote_for",
         education = "what_is_the_highest_degree_or_level_of_school_you_have_completed",   
         ethnicity = "which_race_ethnicity_best_describes_you_please_choose_only_one",
         zipcode = "in_what_zip_code_is_your_home_located_please_enter_a_5_digit_zip_code_for_example_00544_or_94305_if_you_prefer_not_to_answer_that_s_ok_please_type_00000",
         social_media_use = "in_this_survey_we_ll_ask_you_about_social_media_by_which_we_mean_facebook_twitter_you_tube_reddit_and_the_like_do_you_ever_use_social_media",
         president_preference = "think_about_your_network_of_online_friends_and_other_people_you_follow_or_interact_with_on_social_media_what_share_of_them_do_you_think_preferred_the_same_presidential_candidate_as_you",
         news_time = "think_about_the_month_leading_up_to_the_2016_election_on_average_how_many_minutes_per_day_would_you_say_you_spent_reading_watching_or_listening_to_news_about_the_election",
         socialme_media_time = "of_those_minutes_how_many_were_spent_reading_watching_or_listening_to_election_news_on_social_media",
         news_source = "which_of_those_sources_was_your_strong_most_important_strong_source_of_news_and_information_about_the_2016_election",
         francis_question = "x_pope_francis_endorsed_donald_trump",
         francis_seen = "x_pope_francis_endorsed_donald_trump_1",
         francis_believe = "x_1",
         illegalarms_question = "x_the_clinton_foundation_bought_137_million_in_illegal_arms",
         illegalarms_seen = "x_the_clinton_foundation_bought_137_million_in_illegal_arms_1",
         illegalarms_believe = "x_2",
         asylum_question = "x_in_may_2016_ireland_announced_that_it_was_officially_accepting_americans_requesting_political_asylum_from_a_donald_trump_presidency", 
         asylum_seen = "x_in_may_2016_ireland_announced_that_it_was_officially_accepting_americans_requesting_political_asylum_from_a_donald_trump_presidency_1",
         aslum_believe = "x_3",
         sexring_question = "x_at_the_beginning_of_november_the_fbi_uncovered_evidence_of_a_pedophile_sex_ring_run_under_the_guise_of_the_clinton_foundation" ,
         sexring_seen = "x_at_the_beginning_of_november_the_fbi_uncovered_evidence_of_a_pedophile_sex_ring_run_under_the_guise_of_the_clinton_foundation_1" ,
         sexring_believe ="x_4" ,
         comey_question = "x_fbi_director_james_comey_s_october_28th_letter_about_new_developments_in_the_investigation_of_hillary_clinton_s_emails_went_only_to_republican_members_of_congress_and_not_to_democrats" ,
         comey_seen = "x_fbi_director_james_comey_s_october_28th_letter_about_new_developments_in_the_investigation_of_hillary_clinton_s_emails_went_only_to_republican_members_of_congress_and_not_to_democrats_1",
         comey_believe = "x_5",
         taxes_question = "x_under_donald_trump_s_tax_plan_it_is_projected_that_51_of_single_parents_would_see_their_taxes_go_up",
         taxes_seen = "x_under_donald_trump_s_tax_plan_it_is_projected_that_51_of_single_parents_would_see_their_taxes_go_up_1",
         taxes_beleve = "x_6",
         beyonce_question = "x_the_clinton_campaign_secretly_paid_musicians_beyonce_and_jay_z_62_million_to_appear_at_a_rally_in_support_of_hillary_clinton",
         beyonce_seen = "x_the_clinton_campaign_secretly_paid_musicians_beyonce_and_jay_z_62_million_to_appear_at_a_rally_in_support_of_hillary_clinton_1",
         beyonnce_believe = "x_7",
         puertorico_question = "x_donald_trump_threatened_to_deport_puerto_rican_broadway_star_lin_manuel_miranda_not_realizing_that_puerto_rico_is_a_u_s_territory_and_puerto_ricans_are_u_s_citizens",
         puertorico_seen = "x_donald_trump_threatened_to_deport_puerto_rican_broadway_star_lin_manuel_miranda_not_realizing_that_puerto_rico_is_a_u_s_territory_and_puerto_ricans_are_u_s_citizens_1",
         puertorico_believe = "x_8",
         liar_question = "x_hillary_clinton_s_first_name_was_spelled_with_an_extra_i_hilliary_with_the_word_liar_in_the_middle_on_election_ballots_printed_for_use_in_lonoke_county_arkansas",
         liar_seen = "x_hillary_clinton_s_first_name_was_spelled_with_an_extra_i_hilliary_with_the_word_liar_in_the_middle_on_election_ballots_printed_for_use_in_lonoke_county_arkansas_1",
         liar_believe = "x_9",
         scheme_question = "x_leaked_documents_reveal_that_the_clinton_campaign_planned_a_scheme_to_offer_to_drive_republican_voters_to_the_polls_but_then_take_them_to_the_wrong_place",
         shceme_seen = "x_leaked_documents_reveal_that_the_clinton_campaign_planned_a_scheme_to_offer_to_drive_republican_voters_to_the_polls_but_then_take_them_to_the_wrong_place_1",
         shceme_believe = "x_10",
         investigation_question = "fbi_director_james_comey_was_secretly_communicating_with_hillary_clinton_about_when_to_release_results_of_the_fbi_investigation_into_clinton_s_private_email_server",
         investigation_seen = "fbi_director_james_comey_was_secretly_communicating_with_hillary_clinton_about_when_to_release_results_of_the_fbi_investigation_into_clinton_s_private_email_server_1",
         investigation_believe = "x_11",
         caribbean_question = "x_clinton_foundation_staff_were_found_guilty_of_diverting_funds_to_buy_alcohol_for_expensive_parties_in_the_caribbean",
         caribbean_seen = "x_clinton_foundation_staff_were_found_guilty_of_diverting_funds_to_buy_alcohol_for_expensive_parties_in_the_caribbean_1",
         caribbean_believe = "x_12" ,
         deplorables_question = "x_hillary_clinton_said_that_you_could_put_half_of_trump_s_supporters_into_what_i_call_the_basket_of_deplorables",
         deplorables_seen = "x_hillary_clinton_said_that_you_could_put_half_of_trump_s_supporters_into_what_i_call_the_basket_of_deplorables_1",
         deplorables_believe = "x_13",
         concede_question = "x_at_the_third_presidential_debate_donald_trump_refused_to_say_whether_he_would_concede_the_election_if_he_lost",
         concede_seen = "x_at_the_third_presidential_debate_donald_trump_refused_to_say_whether_he_would_concede_the_election_if_he_lost_1",
         concede_believe = "x_14",
         rally_question = "x_the_musicians_beyonce_and_jay_z_appeared_at_a_rally_in_support_of_hillary_clinton",
         rally_seen = "x_the_musicians_beyonce_and_jay_z_appeared_at_a_rally_in_support_of_hillary_clinton_1",
         rally_believe = "x_15",
         age = "what_is_your_age",
         gender = "what_is_your_gender", 
         income = "how_much_total_combined_money_did_all_members_of_your_household_earn_last_year",
         region = "us_region"
  )

```


# Abstract
“Fake news” has become a recurring theme in American politics since the 2016 U.S. election.  Many have raised the question of whether social media plays a role in spreading political misinformation and disinformation. This paper is a replication study of two economists Allcott and Gentzkow on fake news propogation in the 2016 U.S. election. Both of the authors examined how deliberately fabricated, as opposed to erroneous or biased stories from well-known or little-known sources spread on social media platforms, such as Facebook.By conducting a survey with 1200 participants a few months after the 2016 U.S. election, the authors found that fake news did not swing the election as people barely remembered it.Therefore, people's voting behaviors in the 2016 election had not been affected by fake news in social media.

# Introduction
Written by Stanford University professor Matthew Gentzkow and NYU professor Hunt Allcott, the original paper aims to address the following questions: Has social media become a major platform for people to receive political information? How do American adults trust information they see on social media? How would such information affect their voting behaviors and their candidate preferences? 
Fake news is no news. In fact, it has been permeated in American politics for decades. The following graphs illustrate how the political conspiracy theories spread between 1963 and 2010. We can see that the mostly widely circulated one is that the assassination of Martin Luther King was the act of part of a large conspiracy in 1975. 60 percent of the American population believe that it is true, followed by the second mostly widely spread conspiracy of 2003, where the Bush administration was believed to purposely misled the publi about evidencne that Iraq banned weapons in order to build support for war.If we pay close attention to the conspiracies, it seems that there is no correlation between media and the spread of such conspiracy theories. The graphs above illustrate the political conspiracy theories spread between 1963 and 2010. We can see that the mostly widely circulated one is that the assacination of Martin Luther King was the act of part of a large conspiracy in 1975. 60 percent of the American population believe that it is true, followed by the second mostly widely spread consiracy of 2003, where the Bush administration was believed to purposely misled the publi about evidencne that Iraq banned weapons in order to build support for war.If we pay close attention to the conspiracies, it seems that there is no correlation between media and the spread of such conspiracy theories.

```{r, echo=FALSE,message=FALSE,warning=FALSE}
conspiracy_list <- read.delim("/Users/dans/Documents/Github/Social_media_fake_news/Inputs/Data/113992-V1/election-media-JEP-replication/source/raw/conspiracy-1/list_of_theories.txt",sep ="|", header = TRUE, dec =".")

#paste two columns by year
conspiracy_list$theory_new = paste(conspiracy_list$year, conspiracy_list$theory, sep=":")
```

```{r, echo=FALSE,message=FALSE,warning=FALSE,fig.keep='all'}
conspiracy_list %>% 
  ggplot(aes(factor(theory_new),believe)) +
  geom_col() +
  scale_x_discrete(labels = function(x) stringr::str_wrap(x, width = 60),
                   limits = rev) + # reverse order
  scale_y_continuous(expand = c(0, 0)) +
  #https://stackoverflow.com/questions/61782882/how-to-wrap-an-x-axis-label-when-using-aes-string 
  coord_flip() + 
  ylab("Share of people who believe it is true (%)") +
  #ylim(0, 60) +
  theme_bw() +
  theme(axis.title.y  = element_blank(),
        panel.grid.major = element_blank(),
        #panel.border = element_rect(colour = "black", size=1),
        axis.line = element_line(colour = "black",size = .5)) 
#https://stackoverflow.com/questions/10861773/remove-grid-background-color-and-top-and-right-borders-from-ggplot2 

# To save the ggplot as png
# ggsave(path = "/Users/dans/Documents/Github/Social_media_fake_news/Outputs/Plots", filename = "fig1.png")

``` 


```{r, echo=FALSE,message=FALSE,warning=FALSE,fig.keep='all'}
# Figure 1 with ranked order 
conspiracy_list %>% 
  ggplot(aes(x=reorder(factor(theory_new), -believe),believe)) +
  # https://stackoverflow.com/questions/25664007/reorder-bars-in-geom-bar-ggplot2-by-value
  geom_bar(stat = "identity") +
  scale_x_discrete(labels = function(x) stringr::str_wrap(x, width = 60),
                   limits = rev) + # reverse order
  scale_y_continuous(expand = c(0, 0)) +
  #https://stackoverflow.com/questions/61782882/how-to-wrap-an-x-axis-label-when-using-aes-string 
  coord_flip() + 
  ylab("Share of people who believe it is true (%)") +
  #ylim(0, 60) +
  theme_bw() +
  theme(axis.title.y  = element_blank(),
        panel.grid.major = element_blank(),
        #panel.border = element_rect(colour = "black", size=1),
        axis.line = element_line(colour = "black",size = .5)) 
#https://stackoverflow.com/questions/10861773/remove-grid-background-color-and-top-and-right-borders-from-ggplot2 



```

The authors conducted a survey after the presidential election of 2016 to gather data. Specifically, Gentzkow and Allcott ran an online survey of 1,208 US adults recruited from MonkeyMonday in late November, a few weeks after the election. Given that the nature of the recruitment method, the sample size for the survey was not randomly selected. It it indeed biased and the data may not be representative of the population. The main goal of the survey was designed to obtain information about how people rely on social media as an information source to get informed; how exposure to fake news affects people's political behaviors; who are more likely to believes fake News.

# Data 

Dataset

```{r, echo=FALSE,message=FALSE,warning=FALSE,fig.keep='all'}
fb_share <- 
  read.csv("/Users/dans/Documents/Github/Social_media_fake_news/Inputs/Data/113992-V1/election-media-JEP-replication/source/raw/FakeNews/FB-shares---combined.csv")

fb_share %>% 
  select(Pro,title) %>% 
  group_by(Pro) %>% 
  summarise_each(funs(n_distinct(.))) %>% 
  kbl(caption = "Results") %>%
  kable_classic(full_width = F, html_font = "Cambria")

fb_share[fb_share==""] <- NA

# Notice that Fb_share contains some empty rows at the end of the worksheet.Fill
# them in with NAs

fb_share %>% 
  select(Pro, FB_share) %>% 
  na.omit() %>% 
  group_by(Pro) %>% 
  summarise(total = sum(FB_share)) %>% 
  kbl(caption = "Results") %>%
  kable_classic(full_width = F, html_font = "Cambria")


# # total number of fake news stories shard on FB
# sum(fb_share$FB_share,na.rm=TRUE)
#   
```

As the authors put it, there were far more pro-Trump fake news shares — 30.3 million shares for false stories that favored Trump, versus 7.6 million that favored Clinton.My replicated results confirm that there were 41 fake new stories that had been shared on Facebook regarding Clinton, and 115 regarding Trump. However, the total number of fake news stories shared on Facebook was 31674.9 combined; and it was 5518.6 and 26156.3 for Clinton and Trump respecitively. The auhtors would need to specify how they calculated fake news shares on Facebook. 

Post - election survey 
The study was conducted through a post - [election survey](link https://www.surveymonkey.com/r/RSYD75) and a database to understand how people produce, circulate, and receive political fake news. Alongside questions about the respondents' demographics and political affiliations, the survey asked participants for their “most important source of news and information” about the 2016 election. Then, the respondents were presented  with 15 news headlines, equally split between pro-Clinton and pro-Trump news, including some delibrately fabricated false stories, fake stories that really existed, and some true ones as well, and placebo headlines — which were untrue and made-up claims that were neither real nor fake. The respondents then were asked to indicate  if they "recall seeing this reported or discussed prior to the election?' Following this quesiton, the respondents were asked to evalute the authenticity of the news stories. The question was "At the time of the election, would your best guess have been that this statement was true?"

In addition, to understand how political fake news was produced, circulated and received amongst American adults, after aquiring consent from the survey participants to participate and a promise to provide their best answers, the survey asked the respondents to provide their demographic information by answering question including their party identificaetion/affliation, who and when they voted for in the 2016 presidential election, and their gender, educational background, race/ethnicity, zipcode. The survey also asked about 2016 election news consumption, including how much time they spent on reading, watching, or listening to election news in general and on social media in particular, and asked them to identify the most important source of news and information about the 2016 election. 

Accoriding to the authors, the survey was distributed to 1,208 participants.However, there are 1437 observatiions because some respondents have not completed the survey or have withdrawn from the survey. 

```{r, echo=FALSE,message=FALSE,warning=FALSE,fig.keep='all'}
library(SmartEDA)
# Overview of the data - Type = 1
 kbl(ExpData(data=Survey_clean,type=1))

# # Structure of the data - Type = 2
# ExpData(data=Survey_clean,type=2)

```

# Descriptive analysis of the survey sample 
## Party affliation 
```{r, echo=FALSE,message=FALSE,warning=FALSE,fig.keep='all'}
#recode partyid 
# recode the levels of the variables 
Survey_clean$partyid <- as.factor(Survey_clean$partyid)
levels(Survey_clean$partyid) <- c("Strongly Republican","Weakly Republican","Lean toward Republican party","Independent","Lean toward Democratic party","Weakly Democratic", "Strongly Democratic")

library(forcats)
 


Survey_clean$partyid<- 
  fct_collapse(Survey_clean$partyid,Republican = c("Strongly Republican","Weakly Republican"),
               Democratic = c("Weakly Democratic", "Strongly Democratic"),
               Independent = c("Lean toward Republican party","Lean toward Democratic party"))
  


  
    Survey_clean %>% 
    select(partyid) %>% 
    na.omit() %>% 
    ggplot(aes(x = partyid,
               y = prop.table(stat(count)),
               fill = partyid,
               label = scales::percent(prop.table(stat(count))))) +
    geom_bar(position = "dodge") + 
    geom_text(stat = 'count',
              position = position_dodge(.9), 
              vjust = -0.5, 
              size = 3) + 
    scale_y_continuous(labels = scales::percent) + 
    labs(x = 'Party Alliation',
         y = 'Percentage of respondents')

# compared to the national sample 

# missing values are removed due to that people have not completed the survey 
```

In terms of party arlliation, the sample size contains 49 percent of respondents who identified as Republicans, and 34 percent of respondents who identified as Democrats. However, the proportion is seemingly inconsitent with the polling results from major U.S. polling agencies. According to [Gallup](https://www.pewresearch.org/politics/2018/03/20/1-trends-in-party-affiliation-among-demographic-groups/), "37% of registered voters identified as independents, 33% as Democrats and 26% as Republicans" in the year of 2017. 
The inconsistency is potentially a result of different coding strategies. In the survey, respondents were asked to self identified themselves with one of the following categories, namely, "Strongly Republican","Weakly Republican","Lean toward Republican party","Independent","Lean toward Democratic party","Weakly Democratic", "Strongly Democratic", where the "Lean toward Republican party" and "Lean toward Democratic party" categories can also be lumpped into the "Independent" category. If we lumped the respondents who lean toward either party, then the results would be different as the indepdents would be nearly 41% as the Republicans and Democrats being 35.3 percent and 23.8 percent. In this case, we can conclude that the sample size is skewed toward Republicans. 

## Gender 

```{r, echo=FALSE,message=FALSE,warning=FALSE}
# recode gender 1 as female, 2 as male
Survey_clean$gender <- as.factor(Survey_clean$gender)

Survey_clean <- 
  Survey_clean %>% 
  mutate(gender = ifelse(gender == 1 , "female", "male"))
```

```{r, echo=FALSE,message=FALSE,warning=FALSE,fig.keep='all'}
    Survey_clean %>% 
    select(gender) %>% 
    na.omit() %>% 
    ggplot(aes(x = gender,
               y = prop.table(stat(count)),
               fill = gender,
               label = scales::percent(prop.table(stat(count))))) +
    geom_bar(position = "dodge") + 
    geom_text(stat = 'count',
              position = position_dodge(.9), 
              vjust = -0.5, 
              size = 3) + 
    scale_y_continuous(labels = scales::percent) + 
    labs(x = 'Gender',
         y = 'Percentage of respondents')
```
As the graph above shows, the sample is disproportionately female with nearly 2/3 of the survey respondents were women, and only 1/3 of the respondents were men. 

## education 
```{r, echo=FALSE,message=FALSE,warning=FALSE,fig.keep='all'}
#recode education 
Survey_clean$education <- as.factor(Survey_clean$education)
levels(Survey_clean$education) <- c("Less than a high school diploma","High school diploma or equivalent (for example: GED)","Some college but no degree","Associate's degree","Bachelor's degree","Graduate degree (for example: MA, MBA, JD, PhD)")

# create a new partyid column to store the original partyid data, in order for different analyses
Survey_clean <- 
  Survey_clean %>% 
  mutate(education0 = education)


# plot 
Survey_clean %>% 
  select(education) %>% 
  na.omit() %>% 
    ggplot(aes(x = education,
               y = prop.table(stat(count)),
               fill = education,
               label = scales::percent(prop.table(stat(count))))) +
    geom_bar(position = "dodge") + 
    geom_text(stat = 'count',
              position = position_dodge(.9), 
              vjust = -0.5, 
              size = 3) + 
    scale_y_continuous(labels = scales::percent) + 
    labs(x = 'Level of education',
         y = 'Percentage of respondents') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
The sample is also skewed toward highly educated people. As the plot shows, only 27.6 percent of the survey respondents received a high school diploma or less leducation; while more than 70 percent of the survey participants reported receiving at least some college degree level education, more than 40 percent of them reported holding a bachelor's or higher degree. 


## Ethnicity

```{r, echo=FALSE,message=FALSE,warning=FALSE,fig.keep='all'}

#recode ethnicity
Survey_clean$ethnicity <- as.factor(Survey_clean$ethnicity)
levels(Survey_clean$ethnicity) <- c("American Indian or Alaskan Native","Asian or Pacific Islander","Black or African American","Hispanic","White / Caucasian","Other")


# plot 
Survey_clean %>% 
  select(ethnicity) %>% 
  na.omit() %>% 
    ggplot(aes(x = ethnicity,
               y = prop.table(stat(count)),
               fill = ethnicity,
               label = scales::percent(prop.table(stat(count))))) +
    geom_bar(position = "dodge") + 
    geom_text(stat = 'count',
              position = position_dodge(.9), 
              vjust = -0.5, 
              size = 3) + 
    scale_y_continuous(labels = scales::percent) + 
    labs(x = 'Ethnicity/race',
         y = 'Percentage of respondents') +
   theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

As the graph shows, more than 70% of the study participants were white or Caucasian, suggesting that the sample was not drawn using random sampling techniques. 

In summary, the sample was disproportionaly white, female, andd highy education, which lacks representativeness and needs to be adjusted with weights. 


# survey weights                                  

```{r, echo=FALSE,message=FALSE,warning=FALSE,fig.keep='all'}
library("readxl")
weights <- read_excel("/Users/dans/Documents/Github/Social_media_fake_news/Inputs/Data/113992-V1/election-media-JEP-replication/source/raw/Inputs/Data/PostElectionSurvey/National-population-means-for-weighting.xlsx")

library(kableExtra)
weights  %>%
  select(-Source) %>% 
  kbl(caption = "Average weights table") %>%
  kable_classic(full_width = T, html_font = "Cambria")

```


```{r, echo=FALSE,message=FALSE,warning=FALSE,fig.keep='all'}
weights_all <- 
  read_xlsx("/Users/dans/Documents/Github/Social_media_fake_news/Inputs/Data/113992-V1/election-media-JEP-replication/source/raw/Inputs/Data/PostElectionSurvey/Post-Election Survey Summary Statistics.xlsx")

weights_all %>% 
   kbl(caption = "Sample weights summary") %>%
  kable_classic(full_width = T, html_font = "Cambria")
```

The observations were weighted using weighted means abstracted from national samples for national representativeness. The average weight for education was obtained from the weighted average of American adults who aged 18 and above from 2014 ACS 5-year estimates from United States Census Bureau. Accordingly, respondents who received a bachelor's degree or higher were assigned the weight average of 0.2673650; while other respondents at other levels of education were assigned the average mean of 0.4197737 as the weight. Likewise, for the party identification variable, Respondents who identified with Democrats were assigned the weighted mean of 0.3684771; those who identified themselves as Independents, including Republicans and Democrats who indicated that they leaned toward Independents, were assigned the weighted mean of 0.3429180; For Republican survey participants, they were assigned the average weight of 0.2886049. The weighted means for the party identification were drawns from the survey results of American National Election Studies 2012. For the average of the sample size, 47.1549515 was assigned to the sample as the average age of American adults. In terms of race, the white/Caucasion survey respondnents were assigned with a weighted average of 0.6160000, which represents their proportion of the American population. For sex ratio, Men were assigned with the weighted average of 0.4867939. 


```{r, echo=FALSE,message=FALSE,warning=FALSE,fig.keep='all'}
Survey_clean <- 
Survey_clean %>%
  mutate(partyid_weights = 
           ifelse(grepl("Democrat", partyid), "0.3684771",
                                      ifelse(grepl("Republican", partyid), "0.2886049", "0.3429180")),
         age_weights = "47.1549515",
         gender_weights = 
           ifelse(grepl("female", gender), "0.5132061", "0.4867939"),
         education_weights = 
           ifelse(grepl("school",education), "0.4197737","0.2673650"),
         # ethnicity_weights = 
         #   ifelse(grepl("White",ethnicity),"0.6160000")
         )




# https://rstudio-pubs-static.s3.amazonaws.com/116317_e6922e81e72e4e3f83995485ce686c14.html#/9
```



To sum up, in terms of the survey design, there are a few issues: the survey does not include attention checks.  Attenton checks are a useful tool to to make sure survey respondents are really paying attention, and not simply randomly answer the questions for the sake of completing the survey as quickly as possible.The authors should include such attention check questions to insure the reliability of the survey responses. 
The income variable is missing in the original survey. 


## News headlines 
```{r, echo=FALSE,message=FALSE,warning=FALSE,fig.keep='all'}
survey_structure <- read_xlsx("/Users/dans/Documents/Github/Social_media_fake_news/Inputs/Data/113992-V1/election-media-JEP-replication/source/raw/Inputs/Data/PostElectionSurvey/news_datasource.xlsx")


library(kableExtra)
survey_structure  %>%
  na.omit() %>% 
  rename(Type = `Article Type (BigFake, SmallFake, FakeFake, True)`) %>% 
  select(- `Short Text`) %>% 
  kbl(caption = "Average weights table") %>%
  kable_classic(full_width = T, html_font = "Cambria")
```


The survey participants were presented with 15 headlines, which were equally split between pro-Clinton and pro-Trump news stories. The authors categorized the stories into "BigFake", "SmallFake",FakeFake", "BigTrue", referring to ambigously and unambiguously false stories, and unambiguously true ones, and placebo headlines — which were made-up claims that neither true nor fake news outlets had reported. The parcipants were then asked to report if they had seen it “reported or discussed” during the 2016 U.S. campaign, and how likely they would have been to believe it.
False claims included a rumor that the Pope had endorsed Trump for presidency, and that the FBI found evidence of the Clinton Foundation running a pedophile ring. True ones included Trump refusing to confirm that he would concede the election if he lost, as well as Clinton’s comment about Trump supporters belonging in a “basket of deplorables.” Placebos included claims that either Trump or Clinton campaign staff had diverted funds to buy alcohol for expensive parties.
Since the authors have not clearly explained the differences amongst these therms, especially between "BigFake" and "FakeFake", it seems challenging to differentiate them. According to the authors, there were 30 questions ready to be presented to the respondents, but each respondent would only receive a randomly selected 15 of these stories. 


# Most important news source to get politically informed 

As social media has permeated every aspect of our lives, people have started to heavily rely social media to obtain information. This study tests whether social media has become an important information source from which American adults to get news. In this survey, respondents were asked to report what the most important news sources are for them. Surprisingly, the results suggest show that only 17 percent of the respondents clearly indicated that they used social media as their primary information source. This finding is consistent with thee authors findings. In 2016, people still relied on other communication channels to get informed, especially news websites and cable television. 

```{r, echo=FALSE,message=FALSE,warning=FALSE,fig.keep='all'}
# convert news_source into a factor 
Survey_clean$news_source <- as.factor(Survey_clean$news_source)

#recode variable
# levels(Survey_clean$news_source) <- c("Print newspapers","Radio news","Local television news","National evening network television news (such as ABC World News, CBS Evening News, or NBC Nightly News)","Cable television news (such as CNN, the Fox News cable channel, or MSNBC)","Websites or apps, including news websites or apps (such as NYTimes.com, CNN.com, or FoxNews.com), excluding social media","Social media websites or apps (such as Facebook or Twitter)")

levels(Survey_clean$news_source) <- c("Print newspapers","Radio news","Local tele news","National networks","Cable news","Webs or apps","Social media")

# plot 
Survey_clean %>% 
  select(news_source) %>% 
  na.omit() %>% 
    ggplot(aes(x = news_source,
               y = prop.table(stat(count)),
               fill = news_source,
               label = scales::percent(prop.table(stat(count))))) +
    geom_bar(position = "dodge") + 
    geom_text(stat = 'count',
              position = position_dodge(.9), 
              vjust = -0.5, 
              size = 3) + 
    scale_y_continuous(labels = scales::percent) + 
    labs(x = 'Most important news source',
         y = 'Percentage of respondents') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

## How often do people use social media to get news?
Therefore, people do not use social media as the primary source to get political information. However, it does not mean that social media does not play any role in information consumption. To the contrary, survey results suggest that respondents heavily rely on social media ton follow political news. The results show that people heavily rely on social media to get informed. More than 20 percent of the respondents indicated that they often use social media to get news and more than 25 percent of the respondents often turned to websites and apps to get informed. 

```{r, echo=FALSE,message=FALSE,warning=FALSE,fig.keep='all'}
# recode the levels of the variables 
Survey_clean$social_media <- as.factor(Survey_clean$social_media)
levels(Survey_clean$social_media) <- c("Often","Sometimes","Hardly ever","Never")

Survey_clean$web_ap <- as.factor(Survey_clean$web_ap)
levels(Survey_clean$web_ap) <- c("Often","Sometimes","Hardly ever","Never")

longer_survey_socialmedia <- 
  Survey_clean %>% 
  select(social_media,web_ap) %>% 
  pivot_longer(social_media:web_ap, names_to = "question", values_to = "response")

longer_survey_socialmedia %>% 
  na.omit() %>% 
ggplot(aes(x = response,
           y = (..count..)/sum(..count..)*100,
           fill = question)) +
  geom_bar() +
  facet_wrap(vars(question), ncol = 3) +
  labs(x = "Response (on a 1 to 4 scale)", 
       y = "Perc of respondents",
       title ="How often do you get news from social media/web and applications?")
# Often Sometimes Hardly ever Never
```


# Who believed in political fake news? 

One of the goals of this study was to test if the share of respondents that was truly exposed and believed the average fake news article. STo exam what contributed to the respondents' belivability of such political fake news, the authors established a simple linear model as follows to characterize the potential relationship, 
$$
B_{ij} = aX_i + \alpha + \epsilon
$$
In this model, $B_{ij}$ takes 1 when people believe, takes 0 when people do not believe in the story; and takes 0.5 when people are not sure about the veracity of the story.For example, if headline a is true, then B takes value 1 if person i responded “Yes” to “would your best guess have been that this statement was true?”. $B_{ij}$ is the the dependent variable and a vector $Xi$ in a linear regression. 

```{r, echo=FALSE,message=FALSE,warning=FALSE,fig.keep='all'}
results <- readxl::read_xlsx("/Users/dans/Documents/Github/Social_media_fake_news/Inputs/Data/113992-V1/election-media-JEP-replication/source/raw/Inputs/Data/PostElectionSurvey/Rates of seeing and believing.xlsx")

results %>% 
  kbl(caption = "Model results") %>%
  kable_classic(full_width = T, html_font = "Cambria")
```


This table presents the share people who recall seeing (answered "yes" to the question of "Do you recall seeing this reported or discussed prior to the election?") but not believe, or  recall seeing and believed news headlines. Columns 1 and 4 include only Fake headlines, columns 2 and 5 include only Placebo headlines, and columns 3 and 6 present differences between the previous two columns. Observations are weighted for national representativeness.
Specifically, for the share of people who say they were exposed to the article, we see that Fake and Placebo articles are approximately equally likely to be believed. This is approximately a test of the assumption since all people who recalled eeing Placebo headlines are misremembering, as are almost all people who recalled seeing Fake headlines (for small exposure rates). 


